# -----------------------------
# Split store GPS into separate numeric lat/lon
# ---------------------------
# STEP 1: Load dataset
# ---------------------------
# Read merged dataset with both Vinmonopolet store info and municipality info
#data <- read_excel("final_data_mun.xlsx")
# ---------------------------
# STEP 2: Parse store coordinates
# ---------------------------
# GPS_Coordinates column contains both latitude and longitude as a string separated by ";"
# We split this into two separate numeric columns: store_lat and store_lon
#data <- data %>%
#  separate(GPS_Coordinates, into = c("store_lat", "store_lon"), sep = ";", convert = TRUE) %>%
#  mutate(
#    store_lat = as.numeric(store_lat),   # ensure store latitude is numeric
#    store_lon = as.numeric(store_lon)    # ensure store longitude is numeric
#  )
# -----------------------------
# 4. Build Store Location Matrix
# -----------------------------
# Extract distinct (lon, lat) of all Vinmonopolet stores
#store_locations <- data %>%
#  filter(!is.na(store_lon), !is.na(store_lat)) %>%
# ---------------------------
# STEP 3: Ensure municipality center coordinates are numeric
# ---------------------------
# These are already separate in the dataset, but stored as characters — we convert them
#data <- data %>%
#  mutate(
#    Longitude = as.numeric(Longitude),  # longitude of the municipality center
#    Latitude = as.numeric(Latitude)     # latitude of the municipality center
#  )
# ---------------------------
# STEP 4: Extract store coordinates for distance calculation
# ---------------------------
# We only want to use valid store locations for calculating distances
# (some rows in the dataset are just municipality data with no store info)
#store_data <- data %>%
#  filter(!is.na(store_lat), !is.na(store_lon))
# Extract a unique matrix of all Vinmonopolet store locations
# Format required by geosphere is matrix of (longitude, latitude)
#store_locations <- store_data %>%
#  select(store_lon, store_lat) %>%
#  distinct() %>%
#  as.matrix()
# ---------------------------
# STEP 5: Define function to calculate distance to nearest store
# ---------------------------
# For a given municipality center (lon, lat), compute distance to nearest store
# Uses Haversine formula (accounts for Earth's curvature)
#min_distance_to_store <- function(lon, lat) {
#  if (is.na(lon) || is.na(lat)) {
#    return(NA)  # return NA if municipality coordinates are missing
#  }
#  muni_coord <- matrix(c(lon, lat), nrow = 1)  # convert to matrix format for geosphere
#  dists <- distHaversine(muni_coord, store_locations)  # distances in meters
#  return(min(dists) / 1000)  # convert to kilometers
#}
# ---------------------------
# STEP 6: Apply distance function to each municipality
# ---------------------------
# For each row (i.e., each municipality center), calculate distance to closest Vinmonopolet store
# Note: This includes all rows (even ones without a store)
#data$dist_nearest_store <- mapply(
#  min_distance_to_store,
#  data$Longitude,
#  data$Latitude
#)
# ---------------------------
# STEP 7: Quick check (optional)
# ---------------------------
# Check that coordinates are numeric
#str(data$Longitude)
#str(data$Latitude)
# -----------------------------
# 7. Optional: Drop Redundant Columns
# -----------------------------
#data <- data %>%
#  select(
#    -lat, -lon, -multikurve, -kommunenavn
#  )
# -----------------------------
# 8. Final Checks (Optional)
# -----------------------------
#str(data$dist_nearest_store)
#summary(data$dist_nearest_store)
# -----------------------------
# 9. Does VInmonopolets 30 km threshold 97% goal work based on our data
# -----------------------------
# 1. Total population (all municipalities)
#total_pop <- sum(data$Population, na.rm = TRUE)
# 2. Population in municipalities with distance > 30 km
#pop_far_away <- data %>%
#  filter(dist_nearest_store > 30) %>%
#  summarise(total = sum(Population, na.rm = TRUE)) %>%
#  pull(total)
# 3. Share of population far away
#share_far_away <- pop_far_away / total_pop
# 4. Share WITH access (within 30 km)
#share_within_30km <- 1 - share_far_away
# 5. Print results
#cat(sprintf("Share of population within 30 km of a Vinmonopolet: %.2f%%\n", #share_within_30km * 100))
#cat(sprintf("Target (Vinmonopolet): 97%%\n"))
#underserved <- data %>%
#  filter(dist_nearest_store > 30) %>%
#  select(,Mun_name, Population, dist_nearest_store) %>%
#  arrange(desc(dist_nearest_store))
#print(underserved, n = 50)
# -----------------------------
# 10. Export the final data to an Excel file
# -----------------------------
#library(writexl)
#write_xlsx(data, "final_data_mun_dist.xlsx")
# -----------------------------
### Independent variables merge ###
final_data_mun_dist <- here("Data", "Vinmonopolet", "final_data_mun_dist.xlsx")
# Load data
Vinmonopolet <- read_excel(final_data_mun_dist) %>%
select(-c(Store_ID, Store_Status, Postal_Code, Poststed,
PostnummerKategoriKode, PostnummerKategori, Region_Code,
Municipality_Name)) %>%
mutate(
Municipality_Name = Mun_name,
Region_Name = case_when(
Region_Name == "AUST-AGDER" ~ "Agder",
Region_Name == "VEST-AGDER" ~ "Agder",
Region_Name == "AKERSHUS" ~ "Akershus",
Region_Name == "OPPLAND" ~ "Innlandet",
Region_Name == "BUSKERUD" ~ "Buskerud",
Region_Name == "VESTFOLD" ~ "Vestfold",
Region_Name == "FINNMARK" ~ "Finnmark",
Region_Name == "HEDMARK" ~ "Innlandet",
Region_Name == "MØRE OG ROMSDAL" ~ "Møre og Romsdal",
Region_Name == "NORDLAND" ~ "Nordland",
Region_Name == "OSLO" ~ "Oslo",
Region_Name == "ROGALAND" ~ "Rogaland",
Region_Name == "TELEMARK" ~ "Telemark",
Region_Name == "TROMS" ~ "Troms",
Region_Name == "SØR-TRØNDELAG" ~ "Trøndelag",
Region_Name == "NORD-TRØNDELAG" ~ "Trøndelag",
Region_Name == "SOGN OG FJORDANE" ~ "Vestland",
Region_Name == "HORDALAND" ~ "Vestland",
Region_Name == "ØSTFOLD" ~ "Østfold",
is.na(Region_Name) & str_starts(Municipality_Code, "03") ~ "Oslo",
is.na(Region_Name) & str_starts(Municipality_Code, "11") ~ "Rogaland",
is.na(Region_Name) & str_starts(Municipality_Code, "15") ~ "Møre og Romsdal",
is.na(Region_Name) & str_starts(Municipality_Code, "18") ~ "Nordland",
is.na(Region_Name) & str_starts(Municipality_Code, "31") ~ "Østfold",
is.na(Region_Name) & str_starts(Municipality_Code, "32") ~ "Akershus",
is.na(Region_Name) & str_starts(Municipality_Code, "33") ~ "Buskerud",
is.na(Region_Name) & str_starts(Municipality_Code, "34") ~ "Innlandet",
is.na(Region_Name) & str_starts(Municipality_Code, "39") ~ "Vestfold",
is.na(Region_Name) & str_starts(Municipality_Code, "40") ~ "Telemark",
is.na(Region_Name) & str_starts(Municipality_Code, "42") ~ "Agder",
is.na(Region_Name) & str_starts(Municipality_Code, "46") ~ "Vestland",
is.na(Region_Name) & str_starts(Municipality_Code, "50") ~ "Trøndelag",
is.na(Region_Name) & str_starts(Municipality_Code, "55") ~ "Troms",
is.na(Region_Name) & str_starts(Municipality_Code, "56") ~ "Finnmark",
TRUE ~ Region_Name  # Keep existing Region_Name if no conditions are met
)
) %>%
select(-Mun_name)
# Aggregating per municipality data
Vinmonopolet_market <- Vinmonopolet %>%
group_by(Municipality_Code) %>%
summarise(
Mun_name = first(Municipality_Name),
Region_Name = first(Region_Name),
Population = first(Population),
Area = first(Area),
Number_of_stores = sum(`2024` > 0),  # Count non-zero sales
Sales = sum(`2024`),
Lat = first(Latitude),
Lon = first(Longitude),
Dist_nearest = first(dist_nearest_store),
)
# Scaling the variables that have nt been scaled yet
Vinmonopolet_market <- Vinmonopolet_market %>%
mutate(Population = Population / 1000,
Sales = Sales / 1000)
# Now we have loaded and wrangled the main data set, but we can use some
# new variables for our analysis
## Merge 1: Grensehandel ######################################################
Grensehandel_weights <- here("Data", "Vinmonopolet", "Grensehandel_weights.xlsx")
# Load the weights datas
weights <- read_excel(Grensehandel_weights, skip = 3) %>%
slice(1) %>%
select(-'...1') %>%
mutate(
mean_weight = (as.numeric(`2024K1`) + as.numeric(`2024K2`) + as.numeric(`2024K3`) + as.numeric(`2024K4`)) / 4
)
weight_grensehandel <- weights$mean_weight / 100
# Load the regional data
Grensehandel_regions <- here("Data", "Vinmonopolet", "Grensehandel_regions.xlsx")
regional <- read_excel(Grensehandel_regions)
total_grensehandel <- sum(regional$"2024")
# Calculate grensehandel per region
regional <- regional %>%
rename(
Region = `Fylker`,
Total_sale = `2024`
) %>%
mutate(
Grensehandel = Total_sale * weight_grensehandel
)
# Split the "Vestlandet" region row into three new rows: "Rogaland", "Vestland" and "MC8re og Romsdal"
regional <- regional %>%
rbind(
regional %>% filter(Region == "Vestlandet") %>% mutate(Region = "Rogaland"),
regional %>% filter(Region == "Vestlandet") %>% mutate(Region = "Vestland"),
regional %>% filter(Region == "Vestlandet") %>% mutate(Region = "Møre og Romsdal")
) %>%
filter(Region != "Vestlandet")
# Divide the grensehandel value by three for "Rogaland", "Vestland" and "MC8re og Romsdal"
regional <- regional %>%
mutate(
Grensehandel = case_when(
Region == "Rogaland" ~ Grensehandel * 0.35,
Region == "Vestland" ~ Grensehandel * 0.46,
Region == "Møre og Romsdal" ~ Grensehandel * 0.19,
TRUE ~ Grensehandel  # Keep the original value for other regions
)
)
# Split the "Nord-Norge" region row into three new rows: "Nordland", "Troms" and "Finnmark"
# And divide the grensehandel value by three
regional <- regional %>%
mutate(
Grensehandel = ifelse(Region == "Nord-Norge", Grensehandel / 3, Grensehandel)
) %>%
rbind(
regional %>% filter(Region == "Nord-Norge") %>% mutate(Region = "Nordland"),
regional %>% filter(Region == "Nord-Norge") %>% mutate(Region = "Troms"),
regional %>% filter(Region == "Nord-Norge") %>% mutate(Region = "Finnmark")
) %>%
filter(Region != "Nord-Norge")
# Divide the grensehandel value by three for "Nordland", "Troms" and "Finnmark"
regional <- regional %>%
mutate(
Grensehandel = case_when(
Region == "Nordland" ~ Grensehandel * 0.5,
Region == "Troms" ~ Grensehandel * 0.35,
Region == "Finnmark" ~ Grensehandel * 0.15,
TRUE ~ Grensehandel  # Keep the original value for other regions
)
)
# Split the "Agder, Telemark, Buskerud og Vestfold" column into four new columns: "Agder", "Telemark", "Buskerud" and "Vestfold"
# And divide the grensehandel value by four
regional <- regional %>%
mutate(
Grensehandel = ifelse(Region == "Agder, Telemark, Buskerud og Vestfold", Grensehandel / 4, Grensehandel)
) %>%
rbind(
regional %>% filter(Region == "Agder, Telemark, Buskerud og Vestfold") %>% mutate(Region = "Agder"),
regional %>% filter(Region == "Agder, Telemark, Buskerud og Vestfold") %>% mutate(Region = "Telemark"),
regional %>% filter(Region == "Agder, Telemark, Buskerud og Vestfold") %>% mutate(Region = "Buskerud"),
regional %>% filter(Region == "Agder, Telemark, Buskerud og Vestfold") %>% mutate(Region = "Vestfold")
) %>%
filter(Region != "Agder, Telemark, Buskerud og Vestfold")
# Divide the grensehandel value by four for "Agder", "Telemark", "Buskerud" and "Vestfold"
regional <- regional %>%
mutate(
Grensehandel = case_when(
Region == "Agder" ~ Grensehandel * 0.31,
Region == "Telemark" ~ Grensehandel * 0.17,
Region == "Buskerud" ~ Grensehandel * 0.26,
Region == "Vestfold" ~ Grensehandel * 0.26,
TRUE ~ Grensehandel  # Keep the original value for other regions
)
)
# Removing the "total_sale" column from the regional data set
regional <- regional %>% select(-Total_sale)
# Merge the regional data with the main data set on Region_Name in the Vinmonopolet_market data set and Region in the regional data set
Vinmonopolet_market <- left_join(Vinmonopolet_market, regional, by = c("Region_Name" = "Region"))
# Add a new column "Region_pop" where "Population" is summarized for each region
Vinmonopolet_market <- Vinmonopolet_market %>%
group_by(Region_Name) %>%
mutate(Region_pop = sum(Population)) %>%
ungroup()
Vinmonopolet_market <- Vinmonopolet_market %>%
mutate(Kommune_share = Population / Region_pop,
Grensehandel_mun = Grensehandel * Kommune_share) %>%
select(-c("Region_pop", "Kommune_share", "Grensehandel")) %>%
rename(Grensehandel = Grensehandel_mun)
## Merge 2: Tourism ############################################################
Tourism_xlsx <- here("Data", "Vinmonopolet", "Tourism.xlsx")
# Reading tourism data
Tourism <- read_excel(Tourism_xlsx, skip = 4) %>%
rename(
Mun = '...1',
H = 'Hotell og liknande overnattingsbedrifter',
C = 'Campingplassar, hyttegrender og vandrarheim',
) %>%
select(-'...2') %>%
mutate_at(vars(H, C), ~as.numeric(str_replace_all(., ":", "0"))) %>%
mutate(n_stays = H + C) %>%
separate(Mun, into = c("Municipality_Code", "Municipality_Name"), sep = " ", remove = FALSE) %>%
select(-c("Mun", "H", "C", "Municipality_Name")) %>%
filter(!is.na(Municipality_Code))
# Merging the data
Vinmonopolet_market <- left_join(Vinmonopolet_market, Tourism, by = "Municipality_Code") %>%
mutate(
n_stays = ifelse(is.na(n_stays), 0, n_stays),
n_stays = n_stays / 1000
)
# There is a great deal of missing data, so we do not know the relevance of
# this data yet
## Merge 3: Income #############################################################
# Average monthly salary per inhabitant in the municipality
# Load data
Monthly_Salary <- here("Data", "Vinmonopolet", "Monthly_Salary.xlsx")
data <- read_excel(Monthly_Salary)
# Cleaning data by removing rows with missing values and rows with dots
clean_data <- data %>%
filter(!apply(., 1, function(row) any(grepl("\\.", row)))) %>%
na.omit()
# Remove the last two rows from the data, using tidyverse
clean_data <- clean_data %>%
slice(1:(n() - 2)) %>%
select(-'...2') %>%
rename(
Mun = `12852: Kommunefordelt månedslønn, etter region, statistikkmål, statistikkvariabel, år og arbeidssted/bosted`,
Monthly_salary = '...3'
) %>%
separate(Mun, into = c("Municipality_Code", "Municipality_Name"), sep = " ", remove = FALSE) %>%
select(-c("Municipality_Name", "Mun")) %>%
mutate(Monthly_salary = as.numeric(Monthly_salary),
Monthly_salary = Monthly_salary / 1000)
# Merge with the main data set
Vinmonopolet_market <- left_join(Vinmonopolet_market, clean_data, by = "Municipality_Code")
## Merge 4: Concentration ######################################################
# Load data
Concentration_xlsx <- here("Data", "Vinmonopolet", "Concentration.xlsx")
concentration <- read_excel(Concentration_xlsx, skip = 5) %>%
slice(1:357) %>%
select('...1',
'Spredtbygd strøk...3') %>%
rename(Mun = '...1',
Spread = 'Spredtbygd strøk...3') %>%
separate(Mun, into = c("Municipality_Code", "Municipality_Name"), sep = " ", remove = FALSE) %>%
select(-c("Municipality_Name", "Mun")) %>%
mutate(Spread = as.numeric(Spread),
Spread = Spread / 1000)
# Remove the first two characters of each cell in the "Municpality_Code" column
concentration$Municipality_Code <- substr(concentration$Municipality_Code, 3, nchar(concentration$Municipality_Code))
# Merge with the main data set
Vinmonopolet_market <- left_join(Vinmonopolet_market, concentration, by = "Municipality_Code")
## Merge 5: "Active" stores ####################################################
# Load data
Active_xlsx <- here("Data", "Vinmonopolet", "Active.xlsx")
A1 <- read_excel(Active_xlsx, sheet = 1, skip = 2)
A2 <- read_excel(Active_xlsx, sheet = 2, skip = 2)
# Merge the two data sets
Active <- A1 %>%
bind_rows(A2) %>%
select(-c('1', '...3', Fylke))
# Rename columns
names(Active)[1] <- "Mun_name"
# Remove unncessary spaces and numbers from the "Mun_name" column
Active$Mun_name <- substr(Active$Mun_name, 4, nchar(Active$Mun_name))
Active$Mun_name <- trimws(Active$Mun_name, which = "left")
# Replace norwegian special letters with english ones and make all letters lowercase
Active$Mun_name <- tolower(iconv(Active$Mun_name, from = "UTF-8", to = "ASCII//TRANSLIT"))
# Recode the "Mun_name" column
Active$Mun_name <- case_when(
Active$Mun_name == "hamaroy" ~ "habmer - hamaroy",
Active$Mun_name == "hattfjelldal" ~ "aarborte - hattfjelldal",
Active$Mun_name == "valer (viken)" ~ "valer (ostfold)",
TRUE ~ Active$Mun_name)
# Merge with the main data set
# Make a dummy variable for active stores
Vinmonopolet_market$Active <- ifelse(Vinmonopolet_market$Mun_name %in% Active$Mun_name, 1, 0)
## Write to Excel ##############################################################
# Write to Excel
# write_xlsx(Vinmonopolet_market, "demand_data.xlsx")
### Data preparation ###########################################################
# Rename relevant columns in accordance with tidyverse standards
Vinmonopolet_market <- Vinmonopolet_market %>%
rename(
mun_code = Municipality_Code,
mun_name = Mun_name,
region_Name = Region_Name,
population = Population,
area = Area,
number_of_stores = Number_of_stores,
sales = Sales,
lat = Lat,
lon = Lon,
dist_nearest = Dist_nearest,
grensehandel = Grensehandel,
n_stays = n_stays,
monthly_salary = Monthly_salary,
spread = Spread,
active = Active
)
# Narrowing down the data to only contain relevant markets
# Excluding the largest cities because they are not representative
# Train and test split, training data all observations with a store
train_data <- Vinmonopolet_market %>%
filter(number_of_stores > 0)
# Test data all observations without a store
test_data <- Vinmonopolet_market %>%
filter(number_of_stores == 0)
### Model selection ###########################################################
# Forward selection
forward_model <- step(lm(sales ~ 1, data = train_data),
scope = ~ population + grensehandel + n_stays + monthly_salary + area + number_of_stores + spread,
direction = "forward")
summary(forward_model)
# Backward selection
backward_model <- step(lm(sales ~ population + grensehandel + n_stays + monthly_salary + area + number_of_stores + spread,
data = train_data),
direction = "backward")
summary(backward_model)
lm_Area <- lm(sales ~ area, data = train_data)
summary(lm_Area)
lm_pop <- lm(sales ~ population, data = Vinmonopolet_market)
summary(lm_pop)
small_data <- Vinmonopolet_market %>%
filter(number_of_stores == 1 | 0)
lm_pop_test <- lm(sales ~ population, data = small_data)
summary(lm_pop_test)
# Linear regression model for predicting sales with all the variables
var_test <- lm(sales ~ population + grensehandel + n_stays + monthly_salary + area +
number_of_stores + spread,
data = Vinmonopolet_market)
stargazer(var_test, type = "text")
# From these regressions we see that we want to remove the "Area" and "prop_spread" variables
# from the regressions as they are not significant.
### Demand estimation ##########################################################
## Linear regression
# Predicting sales using the training data
reg1 <- lm(sales ~ population + grensehandel + n_stays + monthly_salary,
data = train_data)
summary(reg1)
# Applying the model on the test data
test_data$sales_pred <- predict(reg1, newdata = test_data)
## Merge predicted data into the original data
# Deselect unnecessary columns to merge the data easier
test_data <- test_data %>%
select(mun_code, sales_pred)
# Merge predicted demand (sales) back into the original data
Vinmonopolet_market <- Vinmonopolet_market %>%
left_join(test_data, by = "mun_code") %>%
mutate(sales = ifelse(sales == 0, sales_pred, sales)) %>%
select(-sales_pred) %>%
mutate(sales = ifelse(sales < 0, 0, sales),
number_of_stores = as.integer(number_of_stores)) %>%
filter(number_of_stores < 2)
# Make sure the factor for Number_of_stores has valid R variable names
# that won't cause errors in caret. For instance, rename "0" -> "NoStore"
# and "1" -> "OneStore".
data_for_logit <- Vinmonopolet_market %>%
mutate(number_of_stores = as.factor(number_of_stores))
# Rename factor levels (originally "0" and "1") to "NoStore" and "OneStore"
data_for_logit$number_of_stores <- factor(
data_for_logit$number_of_stores,
levels = c("0", "1"),
labels = c("NoStore", "OneStore")
)
# Set up k-fold cross-validation parameters
set.seed(123)  # for reproducibility
my_control <- trainControl(
method = "cv",            # k-fold CV
number = 5,               # 5 folds
classProbs = TRUE,        # needed for probability output
summaryFunction = twoClassSummary
)
# Train the logistic model with cross-validation
cv_model <- train(
number_of_stores ~ sales,
data = data_for_logit,
method = "glm",
family = binomial,
trControl = my_control,
metric = "ROC"            # use AUC (Area Under the Curve) as our metric
)
# Review cross-validation results
print(cv_model)
print(cv_model$results)
# Get predicted probabilities from the final trained model
# caret retrains on the entire dataset after CV by default
Vinmonopolet_market$prob <- predict(cv_model, newdata = data_for_logit, type = "prob")[, "OneStore"]
# Use the probabilities for your recommendations
recommended_stores <- Vinmonopolet_market %>%
mutate(number_of_stores = as.integer(as.character(number_of_stores))) %>%
filter(number_of_stores == 0, dist_nearest > 0) %>%
arrange(desc(prob)) %>%
select(mun_name, prob, dist_nearest, sales, population, region_name, active)
# relevant libraries
library(tidyverse)
library(readxl)
library(fastDummies)
library(knitr)
library(stargazer)
library(caret)
library(here)
library(httr)
library(jsonlite)
library(readr)
library(stringr)
library(tidyr) # Load tidyr for unnesting
library(writexl)
library(geosphere)
library(caret)
library(kableExtra)
## Logit regression ############################################################
# Make sure the factor for Number_of_stores has valid R variable names
# that won't cause errors in caret. For instance, rename "0" -> "NoStore"
# and "1" -> "OneStore".
data_for_logit <- Vinmonopolet_market %>%
mutate(number_of_stores = as.factor(number_of_stores))
