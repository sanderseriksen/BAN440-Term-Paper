`Average salary` = mean(lsalary, na.rm = TRUE)
) %>%
kable()
set.seed(123)
trainIndex <- createDataPartition(df$lsalary, p = 0.8, list = FALSE)
trainData <- df[trainIndex, ]
testData <- df[-trainIndex, ]
model_check <- lm(lsalary ~ ., data = df)
summary(model_check)
model_check <- lm(lsalary ~ age + college + grad + comten + ceoten + profits + lsales + lmktval + profmarg, data = df)
summary(model_check)
model_check <- lm(lsalary ~ age + college + grad + comten + ceoten + profits + lsales + lmktval + profmarg, data = df)
mod2 <- lm(lsalary ~ age + college + grad + comtensq + ceotensq + profits + lmkval + profmarg, data = df)
model_check <- lm(lsalary ~ age + college + grad + comten + ceoten + profits + lsales + lmktval + profmarg, data = df)
mod2 <- lm(lsalary ~ age + college + grad + comtensq + ceotensq + profits + lmktval + profmarg, data = df)
summary(model_check)
summary(mod2)
View(df)
View(df)
model_check <- lm(lsalary ~ age + college + grad + comten + ceoten + profits + lsales + lmktval + profmarg, data = df)
summary(model_check)
df <- df %>%
select(lsalary,age,college,grad,comten,ceoten,profits,lsales,lmktval,profmarg)
set.seed(123)
trainIndex <- createDataPartition(df$lsalary, p = 0.8, list = FALSE)
trainData <- df[trainIndex, ]
testData <- df[-trainIndex, ]
lm_model <- lm(lsalary ~ ., data = trainData)
lm_pred <- predict(lm_model, newdata = testData)
lm_rmse <- sqrt(mean((lm_pred - testData$lsalary)^2))
lm_rmse
x <- model.matrix(lsalary ~ ., trainData)[, -1]
y <- trainData$lsalary
lasso_model <- cv.glmnet(x, y, alpha = 1)
lasso_best_lambda <- lasso_model$lambda.min
x_test <- model.matrix(lsalary ~ ., testData)[, -1]
lasso_pred <- predict(lasso_model, s = lasso_best_lambda, newx = x_test)
lasso_rmse <- sqrt(mean((lasso_pred - testData$lsalary)^2))
lasso_rmse
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ lsales, data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
knn_pred <- predict(knn_model, newdata = testData)
knn_rmse <- sqrt(mean((knn_pred - testData$lsalary)^2))
knn_rmse
gam_model <- gam(lsalary ~ s(lsales) + s(mktval), data = trainData)
View(df)
gam_model <- gam(lsalary ~ s(lsales) + s(lmktval), data = trainData)
gam_pred <- predict(gam_model, newdata = testData)
gam_rmse <- sqrt(mean((gam_pred - testData$lsalary)^2))
gam_rmse
results <- data.frame(Model = c("Linear Regression", "LASSO", "KNN", "GAM"),
RMSE = c(lm_rmse, lasso_rmse, knn_rmse, gam_rmse))
print(results)
df$college <- as.factor(df$college)
df$grad <- as.factor(df$grad)
model_check <- lm(lsalary ~ age + college + grad + comten + ceoten + profits + lsales + lmktval + profmarg, data = df)
summary(model_check)
df$college <- as.factor(df$college)
df$grad <- as.factor(df$grad)
model_check <- lm(lsalary ~ age + college + grad + comten + ceoten + profits + lsales + lmktval + profmarg, data = df)
summary(model_check)
df <- df %>%
select(lsalary,age,college,grad,comten,ceoten,profits,lsales,lmktval,profmarg)
set.seed(123)
trainIndex <- createDataPartition(df$lsalary, p = 0.8, list = FALSE)
trainData <- df[trainIndex, ]
testData <- df[-trainIndex, ]
set.seed(123)
trainIndex <- createDataPartition(df$lsalary, p = 0.75, list = FALSE)
trainData <- df[trainIndex, ]
testData <- df[-trainIndex, ]
lm_model <- lm(lsalary ~ ., data = trainData)
lm_pred <- predict(lm_model, newdata = testData)
lm_rmse <- sqrt(mean((lm_pred - testData$lsalary)^2))
lm_rmse
x <- model.matrix(lsalary ~ ., trainData)[, -1]
y <- trainData$lsalary
lasso_model <- cv.glmnet(x, y, alpha = 1)
lasso_best_lambda <- lasso_model$lambda.min
x_test <- model.matrix(lsalary ~ ., testData)[, -1]
lasso_pred <- predict(lasso_model, s = lasso_best_lambda, newx = x_test)
lasso_rmse <- sqrt(mean((lasso_pred - testData$lsalary)^2))
lasso_rmse
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ lsales, data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
knn_pred <- predict(knn_model, newdata = testData)
knn_rmse <- sqrt(mean((knn_pred - testData$lsalary)^2))
knn_rmse
gam_model <- gam(lsalary ~ s(lsales) + s(lmktval), data = trainData)
gam_pred <- predict(gam_model, newdata = testData)
gam_rmse <- sqrt(mean((gam_pred - testData$lsalary)^2))
gam_rmse
results <- data.frame(Model = c("Linear Regression", "LASSO", "KNN", "GAM"),
RMSE = c(lm_rmse, lasso_rmse, knn_rmse, gam_rmse))
print(results)
set.seed(123)
trainIndex <- createDataPartition(df$lsalary, p = 0.5, list = FALSE)
trainData <- df[trainIndex, ]
testData <- df[-trainIndex, ]
lm_model <- lm(lsalary ~ ., data = trainData)
lm_pred <- predict(lm_model, newdata = testData)
lm_rmse <- sqrt(mean((lm_pred - testData$lsalary)^2))
lm_rmse
x <- model.matrix(lsalary ~ ., trainData)[, -1]
y <- trainData$lsalary
lasso_model <- cv.glmnet(x, y, alpha = 1)
lasso_best_lambda <- lasso_model$lambda.min
x_test <- model.matrix(lsalary ~ ., testData)[, -1]
lasso_pred <- predict(lasso_model, s = lasso_best_lambda, newx = x_test)
lasso_rmse <- sqrt(mean((lasso_pred - testData$lsalary)^2))
lasso_rmse
x <- model.matrix(lsalary ~ ., trainData)[, -1]
y <- trainData$lsalary
lasso_model <- cv.glmnet(x, y, alpha = 1)
lasso_best_lambda <- lasso_model$lambda.min
x_test <- model.matrix(lsalary ~ ., testData)[, -1]
lasso_pred <- predict(lasso_model, s = lasso_best_lambda, newx = x_test)
lasso_rmse <- sqrt(mean((lasso_pred - testData$lsalary)^2))
lasso_rmse
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ lsales, data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
knn_pred <- predict(knn_model, newdata = testData)
knn_rmse <- sqrt(mean((knn_pred - testData$lsalary)^2))
knn_rmse
set.seed(123)
trainIndex <- createDataPartition(df$lsalary, p = 0.8, list = FALSE)
trainData <- df[trainIndex, ]
testData <- df[-trainIndex, ]
lm_model <- lm(lsalary ~ ., data = trainData)
lm_pred <- predict(lm_model, newdata = testData)
lm_rmse <- sqrt(mean((lm_pred - testData$lsalary)^2))
lm_rmse
x <- model.matrix(lsalary ~ ., trainData)[, -1]
y <- trainData$lsalary
lasso_model <- cv.glmnet(x, y, alpha = 1)
lasso_best_lambda <- lasso_model$lambda.min
x_test <- model.matrix(lsalary ~ ., testData)[, -1]
lasso_pred <- predict(lasso_model, s = lasso_best_lambda, newx = x_test)
lasso_rmse <- sqrt(mean((lasso_pred - testData$lsalary)^2))
lasso_rmse
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ lsales, data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
knn_pred <- predict(knn_model, newdata = testData)
knn_rmse <- sqrt(mean((knn_pred - testData$lsalary)^2))
knn_rmse
gam_model <- gam(lsalary ~ s(lsales) + s(lmktval), data = trainData)
gam_pred <- predict(gam_model, newdata = testData)
gam_rmse <- sqrt(mean((gam_pred - testData$lsalary)^2))
gam_rmse
results <- data.frame(Model = c("Linear Regression", "LASSO", "KNN", "GAM"),
RMSE = c(lm_rmse, lasso_rmse, knn_rmse, gam_rmse))
print(results)
gam_model <- gam(lsalary ~ s(lsales) + s(lmktval) +s(lceoten), data = trainData)
gam_model <- gam(lsalary ~ s(lsales) + s(lmktval) +s(ceoten), data = trainData)
gam_pred <- predict(gam_model, newdata = testData)
gam_rmse <- sqrt(mean((gam_pred - testData$lsalary)^2))
gam_rmse
gam_model <- gam(lsalary ~ s(lsales) + s(lmktval) +s(ceoten), data = trainData)
gam_pred <- predict(gam_model, newdata = testData)
gam_rmse <- sqrt(mean((gam_pred - testData$lsalary)^2))
gam_rmse
gam_model <- gam(lsalary ~ s(lsales) + s(lmktval) +s(ceoten) + s(profits), data = trainData)
gam_pred <- predict(gam_model, newdata = testData)
gam_rmse <- sqrt(mean((gam_pred - testData$lsalary)^2))
gam_rmse
gam_model <- gam(lsalary ~ s(lsales) + s(lmktval) +s(ceoten), data = trainData)
gam_pred <- predict(gam_model, newdata = testData)
gam_rmse <- sqrt(mean((gam_pred - testData$lsalary)^2))
gam_rmse
gam_model2 <- gam(lsalary ~ s(lsales) + s(comten) +s(ceoten), data = trainData)
gam2_pred <- predict(gam_model2, newdata = testData)
gam2_rmse <- sqrt(mean((gam2_pred - testData$lsalary)^2))
gam2_rmse
results <- data.frame(Model = c("Linear Regression", "LASSO", "KNN", "GAM", "GAM2"),
RMSE = c(lm_rmse, lasso_rmse, knn_rmse, gam_rmse, gam2_rmse))
print(results)
results <- data.frame(Model = c("Linear Regression", "LASSO", "KNN", "GAM", "GAM2"),
RMSE = c(lm_rmse, lasso_rmse, knn_rmse, gam_rmse, gam2_rmse))
kable(results)
# Standardize predictors
scaled_predictors <- scale(predictors)
# Standardize predictors
scaled_predictors <- scale(predictors)
predictors <- ceosal2[, c("lsales", "profits")]
target <- ceosal2$salary
# Handle missing data if necessary
predictors <- na.omit(predictors)
target <- target[!is.na(target)]
# Standardize predictors
scaled_predictors <- scale(predictors)
# Define weights for predictors
weights <- c(0.7, 0.3)  # Assign higher weight to 'sales' predictor, for example
# Function to calculate weighted Euclidean distance
weighted_distance <- function(x1, x2, weights) {
sqrt(sum(weights * (x1 - x2)^2))
}
# Custom KNN implementation
custom_knn <- function(train_data, test_point, train_labels, k, weights) {
distances <- apply(train_data, 1, function(row) {
weighted_distance(as.numeric(row), as.numeric(test_point), weights)
})
# Combine distances with labels
neighbors <- data.frame(distance = distances, label = train_labels)
# Get the K nearest neighbors
nearest_neighbors <- neighbors %>%
arrange(distance) %>%
slice(1:k)
# Return the most common label among nearest neighbors
most_common_label <- names(sort(table(nearest_neighbors$label), decreasing = TRUE))[1]
return(most_common_label)
}
# Split data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(scaled_predictors), size = 0.7 * nrow(scaled_predictors))
train_data <- scaled_predictors[train_indices, ]
test_data <- scaled_predictors[-train_indices, ]
train_labels <- target[train_indices]
test_labels <- target[-train_indices]
# Apply the custom KNN function
k <- 5
predictions <- sapply(1:nrow(test_data), function(i) {
custom_knn(train_data, test_data[i, ], train_labels, k, weights)
})
# Evaluate predictions
print(table(Predicted = predictions, Actual = test_labels))
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ lsales + comten + ceoten, data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
knn_pred <- predict(knn_model, newdata = testData)
knn_rmse <- sqrt(mean((knn_pred - testData$lsalary)^2))
knn_rmse
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ lsales + ceoten, data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
knn_pred <- predict(knn_model, newdata = testData)
knn_rmse <- sqrt(mean((knn_pred - testData$lsalary)^2))
knn_rmse
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ lsales * 0.6+ ceoten* 0.2 * comten * 0.2, data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ lsales * 0.6 + ceoten* 0.2 * comten * 0.2, data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ (lsales * 0.6) + (ceoten* 0.2) + (comten * 0.2), data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
train_control <- trainControl(method = "LOOCV")
knn_model <- train(lsalary ~ (lsales * 0.6) + (ceoten * 0.2) + (comten * 0.2), data = trainData, method = "knn", tuneLength = 10, trControl = train_control)
library(Wooldridge)  # Load the dataset
library(wooldridge)  # Load the dataset
library(caret)       # For preprocessing and model training
library(class)       # For KNN
library(FNN)         # For weighted KNN
library(fnn)         # For weighted KNN
install.packages("FNN")
library(FNN)         # For weighted KNN
# Load dataset
data("ceosal2")
# Inspect data
str(ceosal2)
# Select relevant predictors and target
ceo_data <- ceosal2[, c("lsalary", "sales", "profits", "ceoten", "mktval")]
# Handle missing values (if any)
ceo_data <- na.omit(ceo_data)
# Normalize predictors (important for KNN)
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
ceo_data_norm <- as.data.frame(lapply(ceo_data[, -1], normalize))
ceo_data_norm$lsalary <- ceo_data$lsalary
# Split into train and test sets
set.seed(123)
train_indices <- sample(1:nrow(ceo_data_norm), 0.7 * nrow(ceo_data_norm))
train_data <- ceo_data_norm[train_indices, ]
test_data <- ceo_data_norm[-train_indices, ]
# Function to find the best K value
find_best_k <- function(train_x, train_y, test_x, test_y, max_k = 20) {
rmse_values <- numeric(max_k)
for (k in 1:max_k) {
knn_model <- knn.reg(train = train_x, test = test_x, y = train_y, k = k)
rmse_values[k] <- sqrt(mean((knn_model$pred - test_y)^2))
}
best_k <- which.min(rmse_values)
return(list(best_k = best_k, min_rmse = rmse_values[best_k], rmse_values = rmse_values))
}
# Apply function to normalized data
knn_results <- find_best_k(train_data[, -4], train_data$lsalary, test_data[, -4], test_data$lsalary, max_k = 20)
# Print best K and RMSE
print(paste("Best K:", knn_results$best_k))
print(paste("Minimum RMSE:", knn_results$min_rmse))
# Train final KNN model with best K
final_knn <- knn.reg(train = train_data[, -4], test = test_data[, -4], y = train_data$lsalary, k = knn_results$best_k)
# Evaluate performance
final_rmse <- sqrt(mean((final_knn$pred - test_data$lsalary)^2))
print(paste("Final Model RMSE:", final_rmse))
# Normalize predictors
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
ceosal2_norm <- as.data.frame(lapply(ceosal2[, c("sales", "profits", "ceoten", "mktval")], normalize))
ceosal2_norm$lsalary <- ceosal2$lsalary  # Keeping target variable unchanged
# Split into train and test sets
set.seed(123)
train_indices <- sample(1:nrow(ceosal2_norm), 0.7 * nrow(ceosal2_norm))
train_data <- ceosal2_norm[train_indices, ]
test_data <- ceosal2_norm[-train_indices, ]
# Function to find the best K value
find_best_k <- function(train_x, train_y, test_x, test_y, max_k = 20) {
rmse_values <- numeric(max_k)
for (k in 1:max_k) {
knn_model <- knn.reg(train = train_x, test = test_x, y = train_y, k = k)
rmse_values[k] <- sqrt(mean((knn_model$pred - test_y)^2))
}
best_k <- which.min(rmse_values)
return(list(best_k = best_k, min_rmse = rmse_values[best_k], rmse_values = rmse_values))
}
# Apply function to normalized data
knn_results <- find_best_k(train_data[, -1], train_data$lsalary, test_data[, -1], test_data$lsalary, max_k = 20)
# Print best K and RMSE
print(paste("Best K:", knn_results$best_k))
print(paste("Minimum RMSE:", knn_results$min_rmse))
# Train final KNN model with best K
final_knn <- knn.reg(train = train_data[, -1], test = test_data[, -1], y = train_data$lsalary, k = knn_results$best_k)
# Evaluate performance
final_rmse <- sqrt(mean((final_knn$pred - test_data$lsalary)^2))
print(paste("Final Model RMSE:", final_rmse))
# Normalize predictors
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
ceosal2_norm <- as.data.frame(lapply(ceosal2[, c("sales", "profits", "ceoten", "mktval")], normalize))
ceosal2_norm$lsalary <- ceosal2$lsalary  # Keeping target variable unchanged
# Split into train and test sets
set.seed(123)
train_indices <- sample(1:nrow(ceosal2_norm), 0.8 * nrow(ceosal2_norm))
train_data <- ceosal2_norm[train_indices, ]
test_data <- ceosal2_norm[-train_indices, ]
# Function to find the best K value
find_best_k <- function(train_x, train_y, test_x, test_y, max_k = 20) {
rmse_values <- numeric(max_k)
for (k in 1:max_k) {
knn_model <- knn.reg(train = train_x, test = test_x, y = train_y, k = k)
rmse_values[k] <- sqrt(mean((knn_model$pred - test_y)^2))
}
best_k <- which.min(rmse_values)
return(list(best_k = best_k, min_rmse = rmse_values[best_k], rmse_values = rmse_values))
}
# Apply function to normalized data
knn_results <- find_best_k(train_data[, -1], train_data$lsalary, test_data[, -1], test_data$lsalary, max_k = 20)
# Print best K and RMSE
print(paste("Best K:", knn_results$best_k))
print(paste("Minimum RMSE:", knn_results$min_rmse))
# Train final KNN model with best K
final_knn <- knn.reg(train = train_data[, -1], test = test_data[, -1], y = train_data$lsalary, k = knn_results$best_k)
# Evaluate performance
final_rmse <- sqrt(mean((final_knn$pred - test_data$lsalary)^2))
print(paste("Final Model RMSE:", final_rmse))
# Normalize predictors
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
ceosal2_norm <- as.data.frame(lapply(ceosal2[, c("sales", "profits", "ceoten", "mktval")], normalize))
ceosal2_norm$lsalary <- ceosal2$lsalary  # Keeping target variable unchanged
# Split into train and test sets
set.seed(123)
train_indices <- sample(1:nrow(ceosal2_norm), 0.8 * nrow(ceosal2_norm))
train_data <- ceosal2_norm[train_indices, ]
test_data <- ceosal2_norm[-train_indices, ]
# Function to find the best K value
find_best_k <- function(train_x, train_y, test_x, test_y, max_k = 20) {
rmse_values <- numeric(max_k)
for (k in 1:max_k) {
knn_model <- knn.reg(train = train_x, test = test_x, y = train_y, k = k)
rmse_values[k] <- sqrt(mean((knn_model$pred - test_y)^2))
}
best_k <- which.min(rmse_values)
return(list(best_k = best_k, min_rmse = rmse_values[best_k], rmse_values = rmse_values))
}
# Apply function to normalized data
knn_results <- find_best_k(train_data[, -1], train_data$lsalary, test_data[, -1], test_data$lsalary, max_k = 20)
# Print best K and RMSE
print(paste("Best K:", knn_results$best_k))
print(paste("Minimum RMSE:", knn_results$min_rmse))
# Train final KNN model with best K
final_knn <- knn.reg(train = train_data[, -1], test = test_data[, -1], y = train_data$lsalary, k = knn_results$best_k)
# Evaluate performance
final_rmse <- sqrt(mean((final_knn$pred - test_data$lsalary)^2))
print(paste("Final Model RMSE:", final_rmse))
library(ggplot2)
# Generate RMSE plot for different K values
k_values <- 1:20
rmse_values <- sapply(k_values, function(k) {
knn_model <- knn.reg(train = train_data_norm[, -1], test = test_data_norm[, -1], y = train_data_norm$lsalary, k = k)
sqrt(mean((knn_model$pred - test_data_norm$lsalary)^2))
})
# Normalize predictors
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
ceosal2_norm <- as.data.frame(lapply(ceosal2[, c("sales", "profits", "ceoten", "mktval")], normalize))
ceosal2_norm$lsalary <- ceosal2$lsalary  # Keeping target variable unchanged
# Split into train and test sets
set.seed(123)
train_indices <- sample(1:nrow(ceosal2_norm), 0.8 * nrow(ceosal2_norm))
train_data <- ceosal2_norm[train_indices, ]
test_data <- ceosal2_norm[-train_indices, ]
# Function to find the best K value
find_best_k <- function(train_x, train_y, test_x, test_y, max_k = 20) {
rmse_values <- numeric(max_k)
for (k in 1:max_k) {
knn_model <- knn.reg(train = train_x, test = test_x, y = train_y, k = k)
rmse_values[k] <- sqrt(mean((knn_model$pred - test_y)^2))
}
best_k <- which.min(rmse_values)
return(list(best_k = best_k, min_rmse = rmse_values[best_k], rmse_values = rmse_values))
}
# Apply function to normalized data
knn_results <- find_best_k(train_data[, -1], train_data$lsalary, test_data[, -1], test_data$lsalary, max_k = 20)
# Print best K and RMSE
print(paste("Best K:", knn_results$best_k))
print(paste("Minimum RMSE:", knn_results$min_rmse))
# Train final KNN model with best K
final_knn <- knn.reg(train = train_data[, -1], test = test_data[, -1], y = train_data$lsalary, k = knn_results$best_k)
# Evaluate performance
final_rmse <- sqrt(mean((final_knn$pred - test_data$lsalary)^2))
print(paste("Final Model RMSE:", final_rmse))
library(ggplot2)
# Generate RMSE plot for different K values
k_values <- 1:20
rmse_values <- sapply(k_values, function(k) {
knn_model <- knn.reg(train = train_data[, -1], test = test_data_norm[, -1], y = train_data_norm$lsalary, k = k)
sqrt(mean((knn_model$pred - test_data_norm$lsalary)^2))
})
library(ggplot2)
# Generate RMSE plot for different K values
k_values <- 1:20
rmse_values <- sapply(k_values, function(k) {
knn_model <- knn.reg(train = train_data[, -1], test = test_data_norm[, -1], y = train_data$lsalary, k = k)
sqrt(mean((knn_model$pred - test_data_norm$lsalary)^2))
})
library(ggplot2)
# Generate RMSE plot for different K values
k_values <- 1:20
rmse_values <- sapply(k_values, function(k) {
knn_model <- knn.reg(train = train_data[, -1], test = test_data[, -1], y = train_data$lsalary, k = k)
sqrt(mean((knn_model$pred - test_data$lsalary)^2))
})
# Plot RMSE vs K
ggplot(data.frame(k_values, rmse_values), aes(x = k_values, y = rmse_values)) +
geom_line() + geom_point() +
labs(title = "K vs RMSE", x = "Number of Neighbors (K)", y = "RMSE") +
theme_minimal()
setwd("C:/Users/oyaod/OneDrive/Skrivebord/Spring_2025/Ban440/Eksamen/BAN440-Term-Paper/Data/Vinmonopolet")
# Importing libraries
library(tidyverse)
library(readxl)
# Set locale to UTF-8
Sys.setlocale("LC_ALL", "en_US.UTF-8")
# Define the path to your Excel file
file_path <- "Vinmonopolet_2024.xlsx"
# Get the names of all sheets in the Excel file
sheet_names <- excel_sheets(file_path)
# Read each sheet into a list of data frames, skipping the first row
list_of_dfs <- lapply(sheet_names, function(sheet) {
read_excel(file_path, sheet = sheet, skip = 2)
})
# Combine all data frames into a single data frame
combined_data <- bind_rows(list_of_dfs)
# View the combined data frame
print(combined_data)
# Unique values in the first column
unique_values <- unique(combined_data$...1)
print(unique_values)
# Define the values to filter out
values_to_exclude <- c(
"Svakvin", "R??dvin", "Hvitvin", "Musserende vin", "Ros??vin",
"Perlende vin", "Aromatisert vin", "Sider", "Fruktvin",
"Brennevin", "Vodka", "Lik??r", "Whisky", "Akevitt",
"Brennevin, annet", "Gin", "Druebrennevin",
"Brennevin, n??ytralt < 37,5 %", "Rom", "Bitter",
"Fruktbrennevin", "Genever", "??l", "Alkoholfritt", "Sterkvin", "Totalsum",
"eLager"
)
# Filter out the specified values from the first column
filtered_data <- combined_data %>%
filter(!.[[1]] %in% values_to_exclude)
# View the filtered data
print(filtered_data)
# Importing libraries
library(tidyverse)
library(readxl)
# Set locale to UTF-8
Sys.setlocale("LC_ALL", "en_US.UTF-8")
# Define the path to your Excel file
file_path <- "Vinmonopolet_2024.xlsx"
# Get the names of all sheets in the Excel file
sheet_names <- excel_sheets(file_path)
# Read each sheet into a list of data frames, skipping the first row
list_of_dfs <- lapply(sheet_names, function(sheet) {
read_excel(file_path, sheet = sheet, skip = 2)
})
# Combine all data frames into a single data frame
combined_data <- bind_rows(list_of_dfs)
# View the combined data frame
print(combined_data)
# Unique values in the first column
unique_values <- unique(combined_data$...1)
print(unique_values)
# Define the values to filter out
values_to_exclude <- c(
"Svakvin", "R??dvin", "Hvitvin", "Musserende vin", "Ros??vin",
"Perlende vin", "Aromatisert vin", "Sider", "Fruktvin",
"Brennevin", "Vodka", "Lik??r", "Whisky", "Akevitt",
"Brennevin, annet", "Gin", "Druebrennevin",
"Brennevin, n??ytralt < 37,5 %", "Rom", "Bitter",
"Fruktbrennevin", "Genever", "??l", "Alkoholfritt", "Sterkvin", "Totalsum",
"eLager"
)
# Filter out the specified values from the first column
filtered_data <- combined_data %>%
filter(!.[[1]] %in% values_to_exclude)
# View the filtered data
print(filtered_data)
View(combined_data)
View(list_of_dfs)
View(filtered_data)
View(filtered_data)
