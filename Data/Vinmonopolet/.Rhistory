combined_data$...1 <- trimws(combined_data$...1)
# Define the values to filter out
values_to_exclude <- c(
"Svakvin", "Rødvin", "Hvitvin", "Musserende vin", "Rosévin",
"Perlende vin", "Aromatisert vin", "Sider", "Fruktvin",
"Brennevin", "Vodka", "Likør", "Whisky", "Akevitt",
"Brennevin, annet", "Gin", "Druebrennevin",
"Brennevin, nøytralt < 37,5 %", "Rom", "Bitter",
"Fruktbrennevin", "Genever", "Øl", "Alkoholfritt", "Sterkvin", "Totalsum",
"eLager"
)
# Column names of combined data
colnames(combined_data)
# Filter out the specified values from the first column
filtered_data <- combined_data %>%
mutate("2024" = as.numeric(`2024`),
"Store" = as.character(`...1`)) %>%
filter(!.[[1]] %in% values_to_exclude) %>%
select("Store", "2024")
# View the filtered data
print(filtered_data)
library(readxl)
library(dplyr)
# Load the postal code dataset
postal_data <- read_excel("dimpostnummer.xlsx")
# Rename columns to match their purpose in final_data
postal_data <- postal_data %>%
rename(
Postal_Code = `Postnummer`,           # Postal code
Municipality_Code = `KommuneKode`,    # Municipality code
Municipality_Name = `Kommune`,        # Municipality name
Region_Code = `FylkeKode`,            # Region code
Region_Name = `Fylke`,                # Region name
Latitude = `Latitude`,                # Latitude
Longitude = `Longitude`               # Longitude
)
# Convert Postal_Code to numeric to ensure a proper join
postal_data <- postal_data %>%
mutate(Postal_Code = as.numeric(Postal_Code))
final_data <- final_data %>%
mutate(Postal_Code = as.numeric(Postal_Code))
# Merge final_data (stores & revenue) with postal_data (municipality info)
final_data <- final_data %>%
left_join(postal_data, by = "Postal_Code")
# View merged dataset
head(final_data)
View(final_data)
# Importing libraries
library(tidyverse)
library(readxl)
library(writexl)
# Set locale to UTF-8
Sys.setlocale("LC_ALL", "en_US.UTF-8")
# Define the path to your Excel file
file_path <- "Vinmonopolet_2024.xlsx"
# Get the names of all sheets in the Excel file
sheet_names <- excel_sheets(file_path)
# Read each sheet into a list of data frames, skipping the first row
list_of_dfs <- lapply(sheet_names, function(sheet) {
read_excel(file_path, sheet = sheet, skip = 2)
})
# Combine all data frames into a single data frame
combined_data <- bind_rows(list_of_dfs)
# View the combined data frame
print(combined_data)
# Unique values in the first column
unique_values <- unique(combined_data$...1)
print(unique_values)
# Transforming to normal characters
combined_data$...1 <- iconv(combined_data$...1, from = "UTF-8", to = "ASCII//TRANSLIT")
combined_data$...1 <- trimws(combined_data$...1)
# Define the values to filter out
values_to_exclude <- c(
"Svakvin", "Rødvin", "Hvitvin", "Musserende vin", "Rosévin",
"Perlende vin", "Aromatisert vin", "Sider", "Fruktvin",
"Brennevin", "Vodka", "Likør", "Whisky", "Akevitt",
"Brennevin, annet", "Gin", "Druebrennevin",
"Brennevin, nøytralt < 37,5 %", "Rom", "Bitter",
"Fruktbrennevin", "Genever", "Øl", "Alkoholfritt", "Sterkvin", "Totalsum",
"eLager"
)
# Column names of combined data
colnames(combined_data)
# Filter out the specified values from the first column
filtered_data <- combined_data %>%
mutate("2024" = as.numeric(`2024`),
"Store" = as.character(`...1`)) %>%
filter(!.[[1]] %in% values_to_exclude) %>%
select("Store", "2024")
# View the filtered data
print(filtered_data)
# Export the filtered data to an Excel file
write_xlsx(filtered_data, "filtered_data.xlsx")
-
-
-
-
-
-
# Load necessary libraries
library(httr)
library(jsonlite)
library(dplyr)
library(readr)
# Define API URL
url <- "https://apis.vinmonopolet.no/stores/v0/details"
# Define your subscription key (replace with your actual key)
subscription_key <- "3b5b02c6793240fe9e6cb6d176e110e0"
# Send GET request with subscription key in header
response <- GET(url,
add_headers(
Accept = "application/json",
`Ocp-Apim-Subscription-Key` = subscription_key  # API authentication
))
# Check response status
if (status_code(response) == 200) {
# Convert API response to JSON and store it
data <- content(response, as = "text", encoding = "UTF-8")
store_data <- fromJSON(data)
# View first few rows
print(head(store_data))
} else {
print(paste("Error:", status_code(response)))
}
# Transforming to normal characters
store_data$storeName <- iconv(store_data$storeName, from = "UTF-8", to = "ASCII//TRANSLIT")
store_data$storeName <- trimws(store_data$storeName)
# Load necessary libraries
library(dplyr)
library(stringr)
library(tidyr) # Load tidyr for unnesting
library(tidyverse)
# Ensure store_data_clean is correctly formatted
store_data_clean <- store_data %>%
unnest_wider(address) %>%  # Expands nested address fields
select(
storeId,
storeName,
status,
postalCode,
city,
gpsCoord
) %>%
rename(
Store_ID = storeId,
Store_Name = storeName,
Store_Status = status,
Postal_Code = postalCode,
City = city,
GPS_Coordinates = gpsCoord
)
# Standardize store names to improve matching
filtered_data <- filtered_data %>%
mutate(Store = str_trim(str_to_lower(Store)))  # Trim spaces and convert to lowercase
store_data_clean <- store_data_clean %>%
mutate(Store_Name = str_trim(str_to_lower(Store_Name)))  # Trim spaces and convert to lowercase
# Merge filtered_data (sales) with store_data_clean (store details)
final_data <- filtered_data %>%
left_join(store_data_clean, by = c("Store" = "Store_Name"))  # Match by store name
# Check merged data
head(final_data)
View(final_data)
## Vinmonopolet data wrangling ###
# Importing libraries
library(tidyverse)
library(readxl)
library(writexl)
# Importing libraries
library(tidyverse)
library(readxl)
library(writexl)
# Set locale to UTF-8
Sys.setlocale("LC_ALL", "en_US.UTF-8")
# Define the path to your Excel file
file_path <- "Vinmonopolet_2024.xlsx"
# Get the names of all sheets in the Excel file
sheet_names <- excel_sheets(file_path)
# Read each sheet into a list of data frames, skipping the first row
list_of_dfs <- lapply(sheet_names, function(sheet) {
read_excel(file_path, sheet = sheet, skip = 2)
})
# Combine all data frames into a single data frame
combined_data <- bind_rows(list_of_dfs)
# View the combined data frame
print(combined_data)
# Unique values in the first column
unique_values <- unique(combined_data$...1)
print(unique_values)
# Transforming to normal characters
combined_data$...1 <- iconv(combined_data$...1, from = "UTF-8", to = "ASCII//TRANSLIT")
combined_data$...1 <- trimws(combined_data$...1)
# Define the values to filter out
values_to_exclude <- c(
"Svakvin", "Rodvin", "Hvitvin", "Musserende vin", "Rosevin",
"Perlende vin", "Aromatisert vin", "Sider", "Fruktvin",
"Brennevin", "Vodka", "Likor", "Whisky", "Akevitt",
"Brennevin, annet", "Gin", "Druebrennevin",
"Brennevin, noytralt < 37,5 %", "Rom", "Bitter",
"Fruktbrennevin", "Genever", "øl", "Alkoholfritt", "Sterkvin", "Totalsum",
"eLager"
)
# Column names of combined data
colnames(combined_data)
# Filter out the specified values from the first column
filtered_data <- combined_data %>%
mutate("2024" = as.numeric(`2024`),
"Store" = as.character(`...1`)) %>%
filter(!.[[1]] %in% values_to_exclude) %>%
select("Store", "2024")
# View the filtered data
print(filtered_data)
# Load necessary libraries
library(httr)
# Load necessary libraries
library(httr)
library(jsonlite)
library(dplyr)
library(readr)
# Define API URL
url <- "https://apis.vinmonopolet.no/stores/v0/details"
# Define your subscription key (replace with your actual key)
subscription_key <- "3b5b02c6793240fe9e6cb6d176e110e0"
# Send GET request with subscription key in header
response <- GET(url,
add_headers(
Accept = "application/json",
`Ocp-Apim-Subscription-Key` = subscription_key  # API authentication
))
# Check response status
if (status_code(response) == 200) {
# Convert API response to JSON and store it
data <- content(response, as = "text", encoding = "UTF-8")
store_data <- fromJSON(data)
# View first few rows
print(head(store_data))
} else {
print(paste("Error:", status_code(response)))
}
# Transforming to normal characters
store_data$storeName <- iconv(store_data$storeName, from = "UTF-8", to = "ASCII//TRANSLIT")
store_data$storeName <- trimws(store_data$storeName)
# Load necessary libraries
library(dplyr)
library(stringr)
library(tidyr) # Load tidyr for unnesting
library(tidyverse)
# Ensure store_data_clean is correctly formatted
store_data_clean <- store_data %>%
unnest_wider(address) %>%  # Expands nested address fields
select(
storeId,
storeName,
status,
postalCode,
city,
gpsCoord
) %>%
rename(
Store_ID = storeId,
Store_Name = storeName,
Store_Status = status,
Postal_Code = postalCode,
City = city,
GPS_Coordinates = gpsCoord
)
# Standardize store names to improve matching
filtered_data <- filtered_data %>%
mutate(Store = str_trim(str_to_lower(Store)))  # Trim spaces and convert to lowercase
store_data_clean <- store_data_clean %>%
mutate(Store_Name = str_trim(str_to_lower(Store_Name)))  # Trim spaces and convert to lowercase
# Merge filtered_data (sales) with store_data_clean (store details)
final_data <- filtered_data %>%
left_join(store_data_clean, by = c("Store" = "Store_Name"))  # Match by store name
# Check merged data
head(final_data)
# Importing libraries
library(tidyverse)
library(readxl)
library(writexl)
# Set locale to UTF-8
Sys.setlocale("LC_ALL", "en_US.UTF-8")
# Define the path to your Excel file
file_path <- "Vinmonopolet_2024.xlsx"
# Get the names of all sheets in the Excel file
sheet_names <- excel_sheets(file_path)
# Read each sheet into a list of data frames, skipping the first row
list_of_dfs <- lapply(sheet_names, function(sheet) {
read_excel(file_path, sheet = sheet, skip = 2)
})
# Combine all data frames into a single data frame
combined_data <- bind_rows(list_of_dfs)
# View the combined data frame
print(combined_data)
# Unique values in the first column
unique_values <- unique(combined_data$...1)
print(unique_values)
# Transforming to normal characters
combined_data$...1 <- iconv(combined_data$...1, from = "UTF-8", to = "ASCII//TRANSLIT")
combined_data$...1 <- trimws(combined_data$...1)
# Define the values to filter out
values_to_exclude <- c(
"Svakvin", "Rodvin", "Hvitvin", "Musserende vin", "Rosevin",
"Perlende vin", "Aromatisert vin", "Sider", "Fruktvin",
"Brennevin", "Vodka", "Likor", "Whisky", "Akevitt",
"Brennevin, annet", "Gin", "Druebrennevin",
"Brennevin, noytralt < 37,5 %", "Rom", "Bitter",
"Fruktbrennevin", "Genever", "ol", "Alkoholfritt", "Sterkvin", "Totalsum",
"eLager"
)
# Column names of combined data
colnames(combined_data)
# Filter out the specified values from the first column
filtered_data <- combined_data %>%
mutate("2024" = as.numeric(`2024`),
"Store" = as.character(`...1`)) %>%
filter(!.[[1]] %in% values_to_exclude) %>%
select("Store", "2024")
# View the filtered data
print(filtered_data)
# Define the values to filter out
values_to_exclude <- c(
"Svakvin", "Rodvin", "Hvitvin", "Musserende vin", "Rosevin",
"Perlende vin", "Aromatisert vin", "Sider", "Fruktvin",
"Brennevin", "Vodka", "Likor", "Whisky", "Akevitt",
"Brennevin, annet", "Gin", "Druebrennevin",
"Brennevin, noytralt < 37,5 %", "Rom", "Bitter",
"Fruktbrennevin", "Genever", "Ol", "Alkoholfritt", "Sterkvin", "Totalsum",
"eLager"
)
# Column names of combined data
colnames(combined_data)
# Filter out the specified values from the first column
filtered_data <- combined_data %>%
mutate("2024" = as.numeric(`2024`),
"Store" = as.character(`...1`)) %>%
filter(!.[[1]] %in% values_to_exclude) %>%
select("Store", "2024")
# View the filtered data
print(filtered_data)
# Export the filtered data to an Excel file
write_xlsx(filtered_data, "filtered_data.xlsx")
# Load necessary libraries
library(httr)
library(jsonlite)
library(dplyr)
library(readr)
# Define API URL
url <- "https://apis.vinmonopolet.no/stores/v0/details"
# Define your subscription key (replace with your actual key)
subscription_key <- "3b5b02c6793240fe9e6cb6d176e110e0"
# Send GET request with subscription key in header
response <- GET(url,
add_headers(
Accept = "application/json",
`Ocp-Apim-Subscription-Key` = subscription_key  # API authentication
))
# Check response status
if (status_code(response) == 200) {
# Convert API response to JSON and store it
data <- content(response, as = "text", encoding = "UTF-8")
store_data <- fromJSON(data)
# View first few rows
print(head(store_data))
} else {
print(paste("Error:", status_code(response)))
}
# Transforming to normal characters
store_data$storeName <- iconv(store_data$storeName, from = "UTF-8", to = "ASCII//TRANSLIT")
store_data$storeName <- trimws(store_data$storeName)
# Load necessary libraries
library(dplyr)
library(stringr)
library(tidyr) # Load tidyr for unnesting
library(tidyverse)
# Ensure store_data_clean is correctly formatted
store_data_clean <- store_data %>%
unnest_wider(address) %>%  # Expands nested address fields
select(
storeId,
storeName,
status,
postalCode,
city,
gpsCoord
) %>%
rename(
Store_ID = storeId,
Store_Name = storeName,
Store_Status = status,
Postal_Code = postalCode,
City = city,
GPS_Coordinates = gpsCoord
)
# Standardize store names to improve matching
filtered_data <- filtered_data %>%
mutate(Store = str_trim(str_to_lower(Store)))  # Trim spaces and convert to lowercase
store_data_clean <- store_data_clean %>%
mutate(Store_Name = str_trim(str_to_lower(Store_Name)))  # Trim spaces and convert to lowercase
# Merge filtered_data (sales) with store_data_clean (store details)
final_data <- filtered_data %>%
left_join(store_data_clean, by = c("Store" = "Store_Name"))  # Match by store name
# Check merged data
head(final_data)
View(final_data)
library(readxl)
library(dplyr)
# Load the postal code dataset
postal_data <- read_excel("dimpostnummer.xlsx")
# Rename columns to match their purpose in final_data
postal_data <- postal_data %>%
rename(
Postal_Code = `Postnummer`,           # Postal code
Municipality_Code = `KommuneKode`,    # Municipality code
Municipality_Name = `Kommune`,        # Municipality name
Region_Code = `FylkeKode`,            # Region code
Region_Name = `Fylke`,                # Region name
Latitude = `Latitude`,                # Latitude
Longitude = `Longitude`               # Longitude
)
# Convert Postal_Code to numeric to ensure a proper join
postal_data <- postal_data %>%
mutate(Postal_Code = as.numeric(Postal_Code))
final_data <- final_data %>%
mutate(Postal_Code = as.numeric(Postal_Code))
# Merge final_data (stores & revenue) with postal_data (municipality info)
final_data <- final_data %>%
left_join(postal_data, by = "Postal_Code")
# View merged dataset
head(final_data)
View(final_data)
# Save final dataset
write_csv(final_data, "Vinmonopolet_Stores_Final_With_Municipality.csv")
# View final dataset
View(final_data)
# Save final dataset
write_csv(final_data, "Vinmonopolet_Stores_Final_With_Municipality.csv")
View(final_data)
View(filtered_data)
View(store_data_clean)
# Load necessary libraries
library(fuzzyjoin)
library(dplyr)
library(stringr)
# Standardize store names in both datasets to lowercase and remove extra spaces
filtered_data <- filtered_data %>%
mutate(Store = str_trim(str_to_lower(Store)))
store_data_clean <- store_data_clean %>%
mutate(Store_Name = str_trim(str_to_lower(Store_Name)))
# Perform a fuzzy join to allow partial matches
final_data <- stringdist_left_join(filtered_data, store_data_clean,
by = c("Store" = "Store_Name"),
method = "jaccard", max_dist = 0.3)  # Adjust max_dist for better matches
# Perform a fuzzy join to allow partial matches
final_data <- stringdist_left_join(filtered_data, store_data_clean,
by = c("Store" = "Store_Name"),
method = "jaccard", max_dist = 0.3)  # Adjust max_dist for better matches
# Load necessary libraries
library(fuzzyjoin)
# Load necessary libraries
install.packages("fuzzyjoin")
library(fuzzyjoin)
library(dplyr)
library(stringr)
# Standardize store names in both datasets to lowercase and remove extra spaces
filtered_data <- filtered_data %>%
mutate(Store = str_trim(str_to_lower(Store)))
store_data_clean <- store_data_clean %>%
mutate(Store_Name = str_trim(str_to_lower(Store_Name)))
# Perform a fuzzy join to allow partial matches
final_data <- stringdist_left_join(filtered_data, store_data_clean,
by = c("Store" = "Store_Name"),
method = "jaccard", max_dist = 0.3)  # Adjust max_dist for better matches
# Check merged dataset
head(final_data)
# Convert Postal_Code to numeric to ensure a proper join
postal_data <- postal_data %>%
mutate(Postal_Code = as.numeric(Postal_Code))
final_data <- final_data %>%
mutate(Postal_Code = as.numeric(Postal_Code))
# Merge with postal data
final_data <- final_data %>%
left_join(postal_data, by = "Postal_Code")
View(final_data)
# Ensure store_data_clean is correctly formatted
store_data_clean <- store_data %>%
unnest_wider(address) %>%  # Expands nested address fields
select(
storeId,
storeName,
status,
postalCode,
city,
gpsCoord
) %>%
rename(
Store_ID = storeId,
Store_Name = storeName,
Store_Status = status,
Postal_Code = postalCode,
City = city,
GPS_Coordinates = gpsCoord
)
# Standardize store names to improve matching
filtered_data <- filtered_data %>%
mutate(Store = str_trim(str_to_lower(Store)))  # Trim spaces and convert to lowercase
store_data_clean <- store_data_clean %>%
mutate(Store_Name = str_trim(str_to_lower(Store_Name)))  # Trim spaces and convert to lowercase
# Merge filtered_data (sales) with store_data_clean (store details)
final_data <- filtered_data %>%
left_join(store_data_clean, by = c("Store" = "Store_Name"))  # Match by store name
# Check merged data
head(final_data)
