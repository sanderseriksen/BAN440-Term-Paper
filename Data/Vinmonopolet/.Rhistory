# Define data sets
x <- c(1, 2, 3, 4, 5)
y <- c(1.88, 4.54, 10.12, 9.14, 11.26)
# a) Prediction for x=3 with R as a calculator
f_hat <- a0 + a1 * x0
df <- as.data.frame(x + y)
View(df)
df <- as.data.frame(x, y)
# Define data sets
data.frame(
x = c(1, 2, 3, 4, 5),
y = c(1.88, 4.54, 10.12, 9.14, 11.26)
)
# Define data sets
df <- data.frame(
x = c(1, 2, 3, 4, 5),
y = c(1.88, 4.54, 10.12, 9.14, 11.26)
)
View(df)
# b) use lm function to fit the same model as in a)
reg1 <- lm(x ~ y, data = df)
View(reg1)
predict?
?predict
predict(reg1)
# a) Prediction for x=3 with R as a calculator
cumsum(df$x * df$y)
a1 <- ((5 * 134.18) - sum(df$x) * sum(df$y))/
5 * sum(df$x)^2 - sum(df$x)^2
a1 <- 2.336
a0 <- 0.38
f_hat <- a0 + a1 * 3
# b) use lm function to fit the same model as in a)
reg1 <- lm(y ~ x, data = df)
predict(reg1)
# K = 3
K3 <- mean(c(4.54, 10.12, 9.14))
# K = 1
K1 <- 10.12
# K = 5
K5 <- mean(df$y)
# d) KNN function in R
knn=function(x0,x,y,K=20)
{
d=abs(x-x0)
o=order(d)[1:K]
ypred=mean(y[o])
return(ypred)
}
knn(3, 3, 10.12, K = 3)
# d) KNN function in R
knn=function(x0,x,y,K)
{
d=abs(x-x0)
o=order(d)[1:K]
ypred=mean(y[o])
return(ypred)
}
knn(3, 3, 10.12, K = 3)
knn(3, 3, 10.12, 3)
knn(3, 1:5, 10.12, 3)
knn(3, df$x, df$y, 3)
install.packages(ISLR)
# Load library
library(ISLR)
install.packages("ISLR")
# Load library
library(ISLR)
College <- College
str(College)
summary(College)
# b) Divide the dataset into a 50/50 training and test data
set.seed(123)
n = nrow(College)
train_indicator = sample(1:n, size = floor(n/2))
train = College[train_indicator,]
test = College[-train_indicator,]
# c) Fit a linear model on the training data
m1 <- lm(Apps ~ Private + Accept, data = train)
summary(m1)
# d) Compute training MSE
pred_train <- predict(m1)
mse_train <- mean((train$Apps - pred_train)^2)
mse_train
m2=lm(Apps ~ Accept, data = train)
summary(m2)
pred_train2=predict(m2)
mse_train2 = mean((train$Apps-pred_train2)ˆ2)
mse_train2
pred_train2 = predict(m2)
mse_train2 = mean((train$Apps-pred_train2)ˆ2)
mse_train2
pred_train2 <- predict(m2)
mse_train2 <- mean((train$Apps-pred_train2)ˆ2)
mse_train2 <- mean((train$Apps-pred_train2)^2)
mse_train2
# f) Test-MSE for the two fitted models
pred_test=predict(m1,newdata = test)
mse_test=mean((test$Apps-pred_test)^2)
mse_test
pred_test2=predict(m2,newdata = test)
mse_test2=mean((test$Apps-pred_test2)^2)
mse_test2
install.packages("FNN")
library(FNN)
knn.reg(train = train, test = test, k = 3, algorithm = College$Apps)
?knn.reg
knn.reg(train = train, test = test, k = 3, algorithm = "Apps")
knn.reg(train = train, test = test, Apps, k = 3)
knn.reg(train = train, test = test, Apps, k = 3, algorithm = "kd_tree")
knn.reg(train = train, test = test, College$Apps, k = 3, algorithm = "kd_tree")
knn.reg(train = train, test = test, College$Apps, k = 3, algorithm = "brute")
install.packages("class")
library(class)
?class
plot(College$Apps, College$Accept)
plot(College$Accept, College$Accept)
x0 <- test$Accept
x <- train$Accept
y <- train$Apps
ntest <- nrow(test)
pred2_test <- matrix(0, ntest, 1)
for (i in 1:ntest) {
pred2_test[i] <- knn(x0[i], x, y, K = 3)
}
testMSE2 <- mean((test$Apps-pred2_test)^2)
testMSE2
update_geom_defaults()
install.packages("gtsummary")
library(tidyverse)
library(stargazer)
library(knitr)
library(lubridate)
library(gtsummary)
setwd("C:/Users/Sander Eriksen/OneDrive - Norwegian School of Economics/NHH/8. semester/BAN440/Term paper/BAN440---Term-Paper/Data/Vinmonopolet")
# --------------------------- API INTEGRATION ---------------------------
# Load necessary libraries
library(httr)
library(jsonlite)
library(dplyr)
library(readr)
# Define API URL
url <- "https://apis.vinmonopolet.no/stores/v0/details"
# Define your subscription key (replace with your actual key)
subscription_key <- "3b5b02c6793240fe9e6cb6d176e110e0"
# Send GET request with subscription key in header
response <- GET(url,
add_headers(
Accept = "application/json",
`Ocp-Apim-Subscription-Key` = subscription_key  # API authentication
))
# Check response status
if (status_code(response) == 200) {
# Convert API response to JSON and store it
data <- content(response, as = "text", encoding = "UTF-8")
store_data <- fromJSON(data)
# View first few rows
print(head(store_data))
} else {
print(paste("Error:", status_code(response)))
}
# --------------------------- Combine API with Vinmonopol Data ---------------------------
# Load necessary libraries
library(dplyr)
library(stringr)
library(tidyr) # Load tidyr for unnesting
library(tidyverse)
# Ensure store_data_clean is correctly formatted
store_data_clean <- store_data %>%
unnest_wider(address) %>%  # Expands nested address fields
select(
storeId,
storeName,
status,
postalCode,
city,
gpsCoord
) %>%
rename(
Store_ID = storeId,
Store_Name = storeName,
Store_Status = status,
Postal_Code = postalCode,
City = city,
GPS_Coordinates = gpsCoord
)
# Transforming to normal characters
store_data_clean$Store_Name <- iconv(store_data_clean$Store_Name, from = "UTF-8", to = "ASCII//TRANSLIT")
store_data_clean$Store_Name <- trimws(store_data_clean$Store_Name)
# Standardize store names to improve matching
filtered_data <- filtered_data %>%
mutate(Store = str_trim(str_to_lower(Store)))  # Trim spaces and convert to lowercase
### Vinmonopolet data wrangling ###
# Importing libraries
library(tidyverse)
library(readxl)
library(writexl)
# Set locale to UTF-8
Sys.setlocale("LC_ALL", "en_US.UTF-8")
# Define the path to your Excel file
file_path <- "Vinmonopolet_2024.xlsx"
# Get the names of all sheets in the Excel file
sheet_names <- excel_sheets(file_path)
# Read each sheet into a list of data frames, skipping the first row
list_of_dfs <- lapply(sheet_names, function(sheet) {
read_excel(file_path, sheet = sheet, skip = 2)
})
# Combine all data frames into a single data frame
combined_data <- bind_rows(list_of_dfs)
# View the combined data frame
print(combined_data)
# Unique values in the first column
unique_values <- unique(combined_data$...1)
print(unique_values)
# Transforming to normal characters
combined_data$...1 <- iconv(combined_data$...1, from = "UTF-8", to = "ASCII//TRANSLIT")
combined_data$...1 <- trimws(combined_data$...1)
# Define the values to filter out
values_to_exclude <- c(
"Svakvin", "Rodvin", "Hvitvin", "Musserende vin", "Rosevin",
"Perlende vin", "Aromatisert vin", "Sider", "Fruktvin",
"Brennevin", "Vodka", "Likor", "Whisky", "Akevitt",
"Brennevin, annet", "Gin", "Druebrennevin",
"Brennevin, noytralt < 37,5 %", "Rom", "Bitter",
"Fruktbrennevin", "Genever", "Ol", "Alkoholfritt", "Sterkvin", "Totalsum",
"eLager"
)
# Column names of combined data
colnames(combined_data)
# Filter out the specified values from the first column
filtered_data <- combined_data %>%
mutate("2024" = as.numeric(`2024`),
"Store" = as.character(`...1`)) %>%
filter(!.[[1]] %in% values_to_exclude) %>%
select("Store", "2024")
# View the filtered data
print(filtered_data)
# Export the filtered data to an Excel file
write_xlsx(filtered_data, "filtered_data.xlsx")
# --------------------------- API INTEGRATION ---------------------------
# Load necessary libraries
library(httr)
library(jsonlite)
library(dplyr)
library(readr)
# Define API URL
url <- "https://apis.vinmonopolet.no/stores/v0/details"
# Define your subscription key (replace with your actual key)
subscription_key <- "3b5b02c6793240fe9e6cb6d176e110e0"
# Send GET request with subscription key in header
response <- GET(url,
add_headers(
Accept = "application/json",
`Ocp-Apim-Subscription-Key` = subscription_key  # API authentication
))
# Check response status
if (status_code(response) == 200) {
# Convert API response to JSON and store it
data <- content(response, as = "text", encoding = "UTF-8")
store_data <- fromJSON(data)
# View first few rows
print(head(store_data))
} else {
print(paste("Error:", status_code(response)))
}
# --------------------------- Combine API with Vinmonopol Data ---------------------------
# Load necessary libraries
library(dplyr)
library(stringr)
library(tidyr) # Load tidyr for unnesting
library(tidyverse)
# Ensure store_data_clean is correctly formatted
store_data_clean <- store_data %>%
unnest_wider(address) %>%  # Expands nested address fields
select(
storeId,
storeName,
status,
postalCode,
city,
gpsCoord
) %>%
rename(
Store_ID = storeId,
Store_Name = storeName,
Store_Status = status,
Postal_Code = postalCode,
City = city,
GPS_Coordinates = gpsCoord
)
# Transforming to normal characters
store_data_clean$Store_Name <- iconv(store_data_clean$Store_Name, from = "UTF-8", to = "ASCII//TRANSLIT")
store_data_clean$Store_Name <- trimws(store_data_clean$Store_Name)
# Standardize store names to improve matching
filtered_data <- filtered_data %>%
mutate(Store = str_trim(str_to_lower(Store)))  # Trim spaces and convert to lowercase
store_data_clean <- store_data_clean %>%
mutate(Store_Name = str_trim(str_to_lower(Store_Name)))  # Trim spaces and convert to lowercase
# Merge filtered_data (sales) with store_data_clean (store details)
final_data <- filtered_data %>%
left_join(store_data_clean, by = c("Store" = "Store_Name"))  # Match by store name
# Check merged data
head(final_data)
View(final_data)
# Export the final data to an Excel file
write_xlsx(final_data, "final_data.xlsx")
